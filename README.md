# ML-BiGAMP
Matlab code (Matlab2014a) of ML-BiGAMP


This repository provides the implementation of multi-layer bilinear generalized approximate message passing (ML-BiGAMP), which can be found in arXiv: https://arxiv.org/pdf/2007.00436.pdf

This repository includes 7 experiments (please see its branches). 

The 1st experiment (EXP1) verified the consistency of ML-BiGAMP and its SE in 2-layer model. 

(https://github.com/QiuyunZou/ML-BiGAMP/tree/MLBiGAMP-EXP1)

The 2nd experiment (EXP2) provided SNR versus BER of pilot-only, JCD, and Perfect-CSI scheme. 

(https://github.com/QiuyunZou/ML-BiGAMP/tree/MLBiGAMP-EXP2)

The 3rd experiment (EXP3) shown the influence of Kp/Kd on the JCD scheme. 

(https://github.com/QiuyunZou/ML-BiGAMP/tree/MLBiGAMP-EXP3)

The 4th experiment (EXP4) shown the influence of low rank N1 on ML-BiGAMP.

(https://github.com/QiuyunZou/ML-BiGAMP/tree/MLBiGAMP-EXP4)

The 5th experiment (EXP5) conpared ML-BiGAMP with ML-Mat-VAMP in 3-layer model. 

(https://github.com/QiuyunZou/ML-BiGAMP/tree/MLBiGAMP-EXP5)

The 6th experiment (EXP6) shown the consistency of ML-BiGAMP and  its SE in 1-layer model with Bernoulli Gaussian prior. 

(https://github.com/QiuyunZou/ML-BiGAMP/tree/MLBiGAMP-EXP6)

The 7th experiment (EXP7) shown the consistency of ML-BiGAMP and  its SE in 1-layer model with QPSK symbol. 

(https://github.com/QiuyunZou/ML-BiGAMP/tree/MLBiGAMP-EXP7)
